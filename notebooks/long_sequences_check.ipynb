{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import gc\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as ps\n",
    "from scipy.stats import spearmanr\n",
    "from tqdm.auto import tqdm\n",
    "from pathlib import Path\n",
    "from itertools import chain\n",
    "from collections import Counter\n",
    "from abc import ABC, abstractmethod\n",
    "from typing import List, Dict, Tuple, Set\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "import numpy as np\n",
    "import pandas as ps\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6079, 41)\n",
      "(476, 11)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "data_dir = Path('..') / 'data'\n",
    "\n",
    "train_df = ps.read_csv(data_dir / 'train.csv')\n",
    "test_df = ps.read_csv(data_dir / 'test.csv')\n",
    "\n",
    "\n",
    "class AvgModel:\n",
    "    def __init__(self, *models):\n",
    "        self.models = [torch.jit.load(str(m), map_location=device) for m in models]\n",
    "        for model in self.models:\n",
    "            model = model.eval()\n",
    "    \n",
    "    def __call__(self, *inputs):\n",
    "        outputs = []\n",
    "        for m in self.models:\n",
    "            out = m(*inputs)\n",
    "            out = torch.sigmoid(out)\n",
    "            outputs.append(out)\n",
    "        res = torch.stack(outputs, dim=0)\n",
    "        return torch.mean(res, 0)\n",
    "        \n",
    "\n",
    "model = AvgModel(\n",
    "    Path('..') / 'bert_large_f_1.pt',  # 0.3940\n",
    "    Path('..') / 'bert_large_f_2.pt',  # 0.3908\n",
    ")\n",
    "\n",
    "\n",
    "print(train_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = [\n",
    "    'question_asker_intent_understanding',\n",
    "    'question_body_critical',\n",
    "    'question_conversational',\n",
    "    'question_expect_short_answer',\n",
    "    'question_fact_seeking',\n",
    "    'question_has_commonly_accepted_answer',\n",
    "    'question_interestingness_others',\n",
    "    'question_interestingness_self',\n",
    "    'question_multi_intent',\n",
    "    'question_not_really_a_question',\n",
    "    'question_opinion_seeking',\n",
    "    'question_type_choice',\n",
    "    'question_type_compare',\n",
    "    'question_type_consequence',\n",
    "    'question_type_definition',\n",
    "    'question_type_entity',\n",
    "    'question_type_instructions',\n",
    "    'question_type_procedure',\n",
    "    'question_type_reason_explanation',\n",
    "    'question_type_spelling',\n",
    "    'question_well_written',\n",
    "    'answer_helpful',\n",
    "    'answer_level_of_information',\n",
    "    'answer_plausible',\n",
    "    'answer_relevance',\n",
    "    'answer_satisfaction',\n",
    "    'answer_type_instructions',\n",
    "    'answer_type_procedure',\n",
    "    'answer_type_reason_explanation',\n",
    "    'answer_well_written'\n",
    "]\n",
    "\n",
    "text_columns = [\n",
    "    'question_title', \n",
    "    'question_body', \n",
    "    'answer'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import floor, ceil\n",
    "\n",
    "MAX_LEN = 512\n",
    "MAX_QUESTION_LEN = 250\n",
    "MAX_ANSWER_LEN = 259\n",
    "SEP_TOKEN_ID = 102\n",
    "\n",
    "\n",
    "class TransformerFieldsDataset(Dataset):\n",
    "    def __init__(self, \n",
    "                 df: ps.DataFrame,\n",
    "                 tokenizer_dir: str,\n",
    "                 field: str = None,\n",
    "                 train_mode: bool = True,\n",
    "                 **kwargs):\n",
    "        self.df: ps.DataFrame = df\n",
    "        self.field = field\n",
    "        self.train_mode = train_mode\n",
    "        self.tokenizer: BertTokenizer = BertTokenizer.from_pretrained(tokenizer_dir)\n",
    "        self.PAD = self.tokenizer.vocab[\"[PAD]\"]  # or 0 token\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "\n",
    "    def _select_tokens(self, tokens, max_num):\n",
    "        if len(tokens) <= max_num:\n",
    "            return tokens\n",
    "        if self.train_mode:\n",
    "            num_remove = len(tokens) - max_num\n",
    "            remove_start = np.random.randint(0, len(tokens) - num_remove - 1)\n",
    "            return tokens[:remove_start] + tokens[remove_start + num_remove:]\n",
    "        else:\n",
    "            return tokens[:max_num // 2] + tokens[-(max_num - max_num // 2):]\n",
    "\n",
    "    def _build_tokens(self, title, question, answer):\n",
    "        title_body = self._select_tokens(\n",
    "            self.tokenizer.tokenize(title + \",\" + question), \n",
    "            max_num=MAX_QUESTION_LEN\n",
    "        )\n",
    "        ans = self._select_tokens(\n",
    "            self.tokenizer.tokenize(answer), \n",
    "            max_num=MAX_ANSWER_LEN\n",
    "        )\n",
    "        tokens = [\"[CLS]\"] + title_body + [\"[SEP]\"] + ans + [\"[SEP]\"]\n",
    "        return tokens\n",
    "\n",
    "    def _build_segments(self, tokens):\n",
    "        segments = []\n",
    "        # first_sep = True\n",
    "        current_segment_id = 0\n",
    "        for token in tokens:\n",
    "            segments.append(current_segment_id)\n",
    "            if token == \"[SEP]\":\n",
    "                current_segment_id = 1\n",
    "                # if first_sep:\n",
    "                #     first_sep = False \n",
    "                # else:\n",
    "                #     current_segment_id = 1\n",
    "        return segments\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        index = self.df.index[idx]\n",
    "        title = self.df.at[index, \"question_title\"]\n",
    "        body = self.df.at[index, \"question_body\"]\n",
    "        answer = self.df.at[index, \"answer\"]\n",
    "\n",
    "        tokens = self._build_tokens(title, body, answer)\n",
    "        segments = self._build_segments(tokens)\n",
    "        token_ids = self.tokenizer.convert_tokens_to_ids(tokens)\n",
    "        if len(token_ids) < MAX_LEN:\n",
    "            token_ids += [self.PAD] * (MAX_LEN - len(token_ids))\n",
    "        if len(segments) < MAX_LEN:\n",
    "            segments += [self.PAD] * (MAX_LEN - len(segments))\n",
    "        \n",
    "        token_ids = torch.LongTensor(token_ids)\n",
    "        segments = torch.LongTensor(segments)\n",
    "        return token_ids, segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"../data/uncased_L-12_H-768_A-12\")\n",
    "\n",
    "\n",
    "def combined_len(title, body, answer):\n",
    "    title_body = tokenizer.tokenize(title + \",\" + body)\n",
    "    ans = tokenizer.tokenize(answer)\n",
    "    tokens = [\"[CLS]\"] + title_body + [\"[SEP]\"] + ans + [\"[SEP]\"]\n",
    "    return len(tokens)\n",
    "\n",
    "\n",
    "def field_len(feature):\n",
    "    tokens = tokenizer.tokenize(feature)\n",
    "    return len(tokens)\n",
    "\n",
    "\n",
    "for df in (train_df, test_df):\n",
    "    df[\"sequences_len\"] = df.apply(lambda row: combined_len(row[\"question_title\"], row[\"question_body\"], row[\"answer\"]), axis=1)\n",
    "    df[\"title_len\"] = df[\"question_title\"].apply(field_len)\n",
    "    df[\"body_len\"] = df[\"question_body\"].apply(field_len)\n",
    "    df[\"answer_len\"] = df[\"answer\"].apply(field_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_seqs_train_df = train_df[train_df[\"sequences_len\"] > 512]\n",
    "short_seqs_train_df = train_df[train_df[\"sequences_len\"] <= 512]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_spearmanr(trues, preds):\n",
    "    rhos = []\n",
    "    for col_trues, col_pred in zip(trues.T, preds.T):\n",
    "        rhos.append(spearmanr(col_trues, col_pred).correlation)\n",
    "    return np.mean(rhos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## checking performance on long sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test shapes - (1628, 30)\n"
     ]
    }
   ],
   "source": [
    "dataset = TransformerFieldsDataset(\n",
    "    long_seqs_train_df, \n",
    "    tokenizer_dir=\"../data/uncased_L-12_H-768_A-12\",\n",
    "    train_mode=False\n",
    ")\n",
    "loader = DataLoader(\n",
    "    dataset=dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "num_batches = len(loader)\n",
    "preds = []\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (seq, seg) in enumerate(loader):\n",
    "        seq, seg = seq.to(device), seg.to(device)\n",
    "        out = model(seq, seg)\n",
    "        out = out.detach().cpu().numpy()\n",
    "        preds.append(out)\n",
    "        print(f'{batch_idx + 1:4d}/{num_batches}', end='\\r')\n",
    "\n",
    "preds = np.vstack(preds)\n",
    "print(f'Test shapes - {preds.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes (1628, 30) (1628, 30)\n"
     ]
    }
   ],
   "source": [
    "print('Shapes', preds.shape, long_seqs_train_df[targets].values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4610229856230065"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_spearmanr(long_seqs_train_df[targets].values, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test shapes - (4451, 30)\n"
     ]
    }
   ],
   "source": [
    "dataset = TransformerFieldsDataset(\n",
    "    short_seqs_train_df, \n",
    "    tokenizer_dir=\"../data/uncased_L-12_H-768_A-12\",\n",
    "    train_mode=False\n",
    ")\n",
    "loader = DataLoader(\n",
    "    dataset=dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "num_batches = len(loader)\n",
    "preds = []\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (seq, seg) in enumerate(loader):\n",
    "        seq, seg = seq.to(device), seg.to(device)\n",
    "        out = model(seq, seg)\n",
    "        out = out.detach().cpu().numpy()\n",
    "        preds.append(out)\n",
    "        print(f'{batch_idx + 1:4d}/{num_batches}', end='\\r')\n",
    "\n",
    "preds = np.vstack(preds)\n",
    "print(f'Test shapes - {preds.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes (4451, 30) (4451, 30)\n"
     ]
    }
   ],
   "source": [
    "print('Shapes', preds.shape, short_seqs_train_df[targets].values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5087773623224288"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_spearmanr(short_seqs_train_df[targets].values, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
