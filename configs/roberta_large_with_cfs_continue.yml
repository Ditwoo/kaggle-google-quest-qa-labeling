model_params:
  model: model_from_checkpoint
  checkpoint: BEST_STATE
  params:
    model: PTCFS
    pretrain_dir: roberta-large
    num_categories: 6
    num_hosts: 65
    stats_dim: 23
    num_classes: 30
    pad_token: 1

# distributed_params:
#   opt_level: O1
#   syncbn: True

stages:
  state_params:
    main_metric: spearman
    minimize_metric: False

  data_params:
    num_workers: &nw 2
    batch_size: *nw
    tokenizer: roberta-large

  criterion_params:
    criterion: BCEWithLogitsLoss

  callbacks_params:
    loss:
      callback: CriterionCallback
      input_key: targets

    optim:
      callback: OptimizerCallback
      accumulation_steps: 16

    spearman:
      callback: SpearmanScoreCallback
      classes: 30

    saver:
      callback: CheckpointCallback
    
    early_stopping:
      callback: EarlyStoppingCallback
      patience: 3
      metric: spearman
      minimize: False

  stage1:
    state_params:
      num_epochs: 10
    
    optimizer_params:
      optimizer: Adam
      lr: 0.000005