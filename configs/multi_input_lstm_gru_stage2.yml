model_params:
  model: model_from_checkpoint
  checkpoint: logs/multi_input_lstm_gru/checkpoints/best.pth
  params:
    model: MultiInputLstmGru
    embedding_size: 60668
    embedding_dim: 600
    category_embedding_size: 5
    category_embedding_dim: 16
    host_embedding_size: 64
    host_embedding_dim: 32
    hidden_size: 128
    out_rnn_size: 128
    dropout_rate: 0.3
    num_classes: 30

stages:
  state_params:
    main_metric: spearman
    minimize_metric: False

  data_params:
    num_workers: 12
    batch_size: 32
    train_pickle: data/train.pkl
    valid_pickle: data/valid.pkl
    seq_percentile: 95

  criterion_params:
    criterion: BCEWithLogitsLoss
  
  # scheduler_params:
  #   scheduler: ReduceLROnPlateau
  #   factor: 0.2
  #   patience: 3
  #   verbose: True

  callbacks_params:
    loss:
      callback: CriterionCallback
      input_key: targets

    optim:
      callback: OptimizerCallback

    # scheduler:
    #   callback: SchedulerCallback

    spearman:
      callback: SpearmanScoreCallback
      classes: [
        0,   1,  2,  3,  4,  5,  6,  7,  8,  9, 
        10, 11, 12, 13, 14, 15, 16, 17, 18, 19,
        20, 21, 22, 23, 24, 25, 26, 27, 28, 29
      ]

    saver:
      callback: CheckpointCallback

  stage1:
    state_params:
      num_epochs: 30

    optimizer_params:
      optimizer: RAdam
      lr: 0.001

  stage2:
    state_params:
      num_epochs: 30

    optimizer_params:
      optimizer: RAdam
      lr: 0.0001

  finetune:
    state_params:
      num_epochs: 10

    optimizer_params:
      optimizer: RAdam
      lr: 0.00005
